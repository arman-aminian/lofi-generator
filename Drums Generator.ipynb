{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb90b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "\n",
    "from data import *\n",
    "from midi_util import array_to_midi, print_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8b06e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the pitches represented in the MIDI data arrays.\n",
    "# TODO: Read pitches from pitches.txt file in corresponding midi array\n",
    "# directory.\n",
    "PITCHES = [36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 49, 50, 58, 59, 60, 61, 62, 63, 64, 66]\n",
    "# The subset of pitches we'll actually use.\n",
    "IN_PITCHES = [36, 38, 42, 58, 59, 61]#[36, 38, 41, 42, 47, 58, 59, 61]\n",
    "# The pitches we want to generate (potentially for different drum kit)\n",
    "OUT_PITCHES = IN_PITCHES#[54, 56, 58, 60, 61, 62, 63, 64]\n",
    "# The minimum number of hits to keep a drum loop after the types of\n",
    "# hits have been filtered by IN_PITCHES.\n",
    "MIN_HITS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1509c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Network architecture parameters.\n",
    "########################################################################\n",
    "NUM_HIDDEN_UNITS = 128\n",
    "# The length of the phrase from which the predict the next symbol.\n",
    "PHRASE_LEN = 64\n",
    "# Dimensionality of the symbol space.\n",
    "SYMBOL_DIM = 2 ** len(IN_PITCHES)\n",
    "NUM_ITERATIONS = 2\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# VALIDATION_PERCENT = 0.1\n",
    "VALIDATION_PERCENT = 0.001\n",
    "\n",
    "BASE_DIR = './'\n",
    "#BASE_DIR = '/home/ubuntu/neural-beats'\n",
    "\n",
    "#MIDI_IN_DIR = os.path.join(BASE_DIR, 'midi_arrays/mega/')\n",
    "#MIDI_IN_DIR = os.path.join(BASE_DIR, 'midi_arrays/mega/Electronic Live 9 SD/Jungle')\n",
    "MIDI_IN_DIR = os.path.join(BASE_DIR, 'drums midi')\n",
    "#MIDI_IN_DIR = os.path.join(BASE_DIR, 'midi_arrays/mega/Rock Essentials 2 Live 9 SD/Preview Files/Fills/4-4 Fills')\n",
    "\n",
    "MODEL_OUT_DIR = os.path.join(BASE_DIR, 'models')\n",
    "MODEL_NAME = 'drum_generator'\n",
    "TRIAL_DIR = os.path.join(MODEL_OUT_DIR, MODEL_NAME)\n",
    "\n",
    "MIDI_OUT_DIR = os.path.join(TRIAL_DIR, 'gen-midi')\n",
    "\n",
    "LOAD_WEIGHTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98d7f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode each configuration of p pitches, each on or off, as a\n",
    "# number between 0 and 2**p-1.\n",
    "assert len(IN_PITCHES) <= 8, 'Too many configurations for this many pitches!'\n",
    "encodings = {\n",
    "    config : i\n",
    "    for i, config in enumerate(itertools.product([0,1], repeat=len(IN_PITCHES)))\n",
    "}\n",
    "\n",
    "decodings = {\n",
    "    i : config\n",
    "    for i, config in enumerate(itertools.product([0,1], repeat=len(IN_PITCHES)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9180dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.log(a) / temperature\n",
    "    a = a.astype('float64')\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))\n",
    "\n",
    "\n",
    "def encode(midi_array):\n",
    "    '''Encode a folded MIDI array into a sequence of integers.'''\n",
    "    return [\n",
    "        encodings[tuple((time_slice>0).astype(int))]\n",
    "        for time_slice in midi_array\n",
    "    ]\n",
    "\n",
    "\n",
    "def decode(config_ids):\n",
    "    '''Decode a sequence of integers into a folded MIDI array.'''\n",
    "    velocity = 120\n",
    "#     velocity = 1\n",
    "    return velocity * np.vstack(\n",
    "        [list(decodings[id]) for id in config_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc2049e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold(midi_array, pitches):\n",
    "    '''Unfold a folded MIDI array with the given pitches.'''\n",
    "    # Create an array of all the 128 pitches and fill in the\n",
    "    # corresponding pitches.\n",
    "    res = np.zeros((midi_array.shape[0], 128))\n",
    "    assert midi_array.shape[1] == len(pitches), 'Mapping between unequal number of pitches!'\n",
    "    for i in range(len(pitches)):\n",
    "        res[:,pitches[i]] = midi_array[:,i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26f08f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    # Load the data.\n",
    "    # Concatenate all the vectorized midi files.\n",
    "    num_steps = 0\n",
    "\n",
    "    # Sequence of configuration numbers representing combinations of\n",
    "    # active pitches.\n",
    "    config_sequences = []\n",
    "    num_dirs = len([x for x in os.walk(MIDI_IN_DIR)])\n",
    "    assert num_dirs > 0, 'No data found at {}'.format(MIDI_IN_DIR)\n",
    "\n",
    "    in_pitch_indices = [ PITCHES.index(p) for p in IN_PITCHES ]\n",
    "    for dir_idx, (root, dirs, files) in enumerate(os.walk(MIDI_IN_DIR)):\n",
    "        for filename in files:\n",
    "            if filename.split('.')[-1] != 'npy':\n",
    "                continue\n",
    "            array = np.load(os.path.join(root, filename))\n",
    "            if np.sum(np.sum(array[:, in_pitch_indices]>0)) < MIN_HITS:\n",
    "                continue\n",
    "            config_sequences.append(np.array(encode(array[:, in_pitch_indices])))\n",
    "        print('Loaded {}/{} directories'.format(dir_idx + 1, num_dirs))\n",
    "\n",
    "    # Construct labeled examples.\n",
    "    # Use a generator for X and y as the whole dataset may not fit in\n",
    "    # memory.\n",
    "    train_generator = SequenceDataGenerator(config_sequences,\n",
    "                                            phrase_length=PHRASE_LEN,\n",
    "                                            dim=SYMBOL_DIM,\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            is_validation=False,\n",
    "                                            validation_percent=VALIDATION_PERCENT)\n",
    "\n",
    "    valid_generator = SequenceDataGenerator(config_sequences,\n",
    "                                            phrase_length=PHRASE_LEN,\n",
    "                                            dim=SYMBOL_DIM,\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            is_validation=True,\n",
    "                                            validation_percent=VALIDATION_PERCENT)\n",
    "\n",
    "    return config_sequences, train_generator, valid_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "186e8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    # Build the model.\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        NUM_HIDDEN_UNITS,\n",
    "        return_sequences=True,\n",
    "        input_shape=(PHRASE_LEN, SYMBOL_DIM)))\n",
    "    model.add(Dropout(0.3))\n",
    "    '''\n",
    "    model.add(LSTM(\n",
    "        NUM_HIDDEN_UNITS,\n",
    "        return_sequences=True,\n",
    "        input_shape=(SYMBOL_DIM, SYMBOL_DIM)))\n",
    "    model.add(Dropout(0.2))\n",
    "    '''\n",
    "    model.add(LSTM(NUM_HIDDEN_UNITS, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(SYMBOL_DIM))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(learning_rate=1e-03, rho=0.9, epsilon=1e-08))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a313238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, seed, mid_name, temperature=1.0, length=512):\n",
    "    '''Generate sequence using model, seed, and temperature.'''\n",
    "\n",
    "    generated = []\n",
    "    phrase = seed\n",
    "\n",
    "    if not hasattr(temperature, '__len__'):\n",
    "        temperature = [temperature for _ in range(length)]\n",
    "\n",
    "    for temp in temperature:\n",
    "        x = np.zeros((1, PHRASE_LEN, SYMBOL_DIM))\n",
    "        for t, config_id in enumerate(phrase):\n",
    "            x[0, t, config_id] = 1\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_id = sample(preds, temp)\n",
    "\n",
    "        generated += [next_id]\n",
    "        phrase = phrase[1:] + [next_id]\n",
    "\n",
    "    # ticks per quarter has negative correlation with drums speed\n",
    "    mid = array_to_midi(unfold(decode(generated), OUT_PITCHES), mid_name, ticks_per_quarter=1200)\n",
    "    mid.save(os.path.join(MIDI_OUT_DIR, mid_name))\n",
    "    return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bfddf926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config_sequences, train_generator, valid_generator):\n",
    "    '''Train model and save weights.'''\n",
    "\n",
    "    # Create the trial directory.\n",
    "    if not os.path.exists(TRIAL_DIR):\n",
    "        os.makedirs(TRIAL_DIR)\n",
    "    # Copy the source file, with a version number, to the trial directory.\n",
    "#     source_filename = '__file__'\n",
    "#     versioned_source_filename = ''.join([\n",
    "#         ''.join(source_filename.split('.')[:-1]),\n",
    "#         '-' + datetime.strftime(datetime.now(), '%Y%m%d%H%M%S') + '.',\n",
    "#         source_filename.split('.')[-1]\n",
    "#     ])\n",
    "#     shutil.copyfile(\n",
    "#         source_filename,\n",
    "#         os.path.join(TRIAL_DIR, versioned_source_filename))\n",
    "\n",
    "\n",
    "    # Initialize the model.\n",
    "    model = init_model()\n",
    "    print(model.summary())\n",
    "\n",
    "    # Train the model\n",
    "    if not os.path.exists(MIDI_OUT_DIR):\n",
    "        os.makedirs(MIDI_OUT_DIR)\n",
    "    if not os.path.exists(MODEL_OUT_DIR):\n",
    "        os.makedirs(MODEL_OUT_DIR)\n",
    "    print('Training the model...')\n",
    "\n",
    "    if LOAD_WEIGHTS:\n",
    "        print('Attempting to load previous weights...')\n",
    "        weights_path = os.path.join(TRIAL_DIR, MODEL_NAME)\n",
    "        if os.path.exists(weights_path):\n",
    "            model.load_weights(weights_path)\n",
    "\n",
    "    best_val_loss = None\n",
    "\n",
    "    sequence_indices = idx_seq_of_length(config_sequences, PHRASE_LEN + 1)\n",
    "    n_points = len(sequence_indices)\n",
    "\n",
    "    nb_val_samples = n_points * VALIDATION_PERCENT\n",
    "    print('Number of training points: {}'.format(n_points))\n",
    "    print('Using {} validation batches'.format(nb_val_samples))\n",
    "\n",
    "    for i in range(NUM_ITERATIONS):\n",
    "        print('Iteration {}'.format(i))\n",
    "\n",
    "        history = model.fit(\n",
    "            train_generator.gen(),\n",
    "#             steps_per_epoch=BATCH_SIZE*512,\n",
    "            steps_per_epoch=BATCH_SIZE*128,\n",
    "            epochs=1,\n",
    "            validation_data=valid_generator.gen(),\n",
    "            validation_steps=nb_val_samples)\n",
    "\n",
    "        val_loss = history.history['val_loss'][-1]\n",
    "        if best_val_loss is None or val_loss < best_val_loss:\n",
    "            print('Best validation loss so far. Saving...')\n",
    "            best_val_loss = val_loss\n",
    "            model.save_weights(os.path.join(TRIAL_DIR, MODEL_NAME),\n",
    "                               overwrite=True)\n",
    "        # Write history.\n",
    "        with open(os.path.join(TRIAL_DIR, 'history.jsonl'), 'a') as fp:\n",
    "            json.dump(history.history, fp)\n",
    "            fp.write('\\n')\n",
    "\n",
    "        # Reset seed so we can compare generated patterns across iterations.\n",
    "        np.random.seed(0)\n",
    "        \n",
    "        sequence_indices = idx_seq_of_length(config_sequences, PHRASE_LEN)\n",
    "        seq_index, phrase_start_index = sequence_indices[\n",
    "            np.random.choice(len(sequence_indices))]\n",
    "        gen_length = 512\n",
    "\n",
    "        # Generate samples.\n",
    "        if not (i > 9 and i % 10 == 0):\n",
    "            continue\n",
    "\n",
    "        for temperature in [0.5, 0.75, 1.0]:\n",
    "            generated = []\n",
    "            phrase = list(\n",
    "                config_sequences[seq_index][\n",
    "                    phrase_start_index: phrase_start_index + PHRASE_LEN])\n",
    "\n",
    "            print('----- Generating with temperature:', temperature)\n",
    "\n",
    "            generate(model,\n",
    "                     phrase,\n",
    "                     'out_{}_{}_{}.mid'.format(gen_length, temperature, i),\n",
    "                     temperature=temperature,\n",
    "                     length=gen_length)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b205574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1/1 directories\n"
     ]
    }
   ],
   "source": [
    "config_sequences, train_generator, valid_generator = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6145e4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 2048, 1024)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(config_sequences[0]),len(config_sequences[1]),len(config_sequences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "036810c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 64, 128)           98816     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 238,656\n",
      "Trainable params: 238,656\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training the model...\n",
      "Attempting to load previous weights...\n",
      "Number of training points: 2347456\n",
      "Using 2347.456 validation batches\n",
      "Iteration 0\n",
      "16384/16384 [==============================] - 5589s 341ms/step - loss: 0.4046 - val_loss: 0.2561\n",
      "Best validation loss so far. Saving...\n",
      "Iteration 1\n",
      "16384/16384 [==============================] - 6054s 370ms/step - loss: 0.2283 - val_loss: 0.1436\n",
      "Best validation loss so far. Saving...\n"
     ]
    }
   ],
   "source": [
    "m = train(config_sequences, train_generator, valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "074fcacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save_weights('./model02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "553b8e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2e72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac536a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
